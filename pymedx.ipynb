{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import  Iterable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pymedx_custom import PubMedArticle, PubMed\n",
    "\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG,datefmt='%H:%M:%S' , format='%(asctime)s.%(msecs)03d - %(module)s/%(funcName)s:%(lineno)d - %(levelname)s - %(message)s')\n",
    "logging.basicConfig(level=logging.INFO,datefmt='%H:%M:%S' , format='%(asctime)s.%(msecs)03d - %(module)s/%(funcName)s:%(lineno)d - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "pubmed = PubMed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(articles: Iterable[PubMedArticle]) -> pd.DataFrame:\n",
    "    \"Construct a DataFrame from a list of PubMedArticle objects\"\n",
    "    \n",
    "    dict_articles = [x.toDict() for x in articles]\n",
    "    print(f\"Total articles: {len(dict_articles)}\")\n",
    "    return pd.DataFrame(dict_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base list of articles is a set of articles where:\n",
    " - Author: Kabashin \n",
    " - or Author: Barcikowski \n",
    " - or Keywords: \"pulsed laser ablation in liquids\" \n",
    " - or Keywords: \"laser ablation in liquids\"\n",
    " - or Keywords: \"nanoparticles\" AND \"laser ablation\"\n",
    " - or Keywords: \"laser fragmentation in liquids\" \n",
    " - Articles published after 1992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = \"Kabashin[AU]\"\n",
    "base = get_df(pubmed.query(author))\n",
    "\n",
    "author = \"Barcikowski[AU]\"\n",
    "base = pd.concat([base, get_df(pubmed.query(author))])\n",
    "\n",
    "keywords = \"pulsed laser ablation in liquids[OT]\"\n",
    "base = pd.concat([base, get_df(pubmed.query(keywords))])\n",
    "\n",
    "keywords = \"laser ablation in liquids[OT]\"\n",
    "base = pd.concat([base, get_df(pubmed.query(keywords))])\n",
    "\n",
    "keywords = \"laser ablation[OT] AND nanoparticles[OT]\"\n",
    "base = pd.concat([base, get_df(pubmed.query(keywords))])\n",
    "\n",
    "keywords = \"laser fragmentation in liquids[OT]\"\n",
    "base = pd.concat([base, get_df(pubmed.query(keywords))])\n",
    "\n",
    "# Drop duplicates\n",
    "base.drop_duplicates(subset='doi', inplace=True)\n",
    "\n",
    "# Drop too old\n",
    "base = base[base['publication_date'] > '1993-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save base articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_csv('base_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of articles, which cite base list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing = pd.DataFrame(columns=base.columns)\n",
    "\n",
    "tot_articles = len(base)\n",
    "for i, pmid in enumerate(base['pmid']):\n",
    "    logging.info(f'Start fetching article {i+1}/{tot_articles} - {pmid}')\n",
    "    articles = pubmed.getCitingArticles(pmid)\n",
    "    dict_articles = [x.toDict() for x in articles]\n",
    "    citing = pd.concat([citing, pd.DataFrame(dict_articles)], ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "citing.drop_duplicates(subset='doi', inplace=True)\n",
    "\n",
    "# Drop articles from base list\n",
    "citing = citing[~citing.doi.isin(base.doi)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get references of base list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = pd.DataFrame(columns=base.columns)\n",
    "\n",
    "tot_articles = len(base)\n",
    "for i, ref_list in enumerate(base['references'].dropna()):\n",
    "    logging.info(f'Start fetching refernces for article {i+1}/{tot_articles} - {ref_list}')\n",
    "    if ref_list:\n",
    "        ref_list = eval(ref_list)\n",
    "        ids = [ref['pmid'] for ref in ref_list if ref['pmid'] is not None]\n",
    "        logging.info(f'Fetching {len(ids)} references...')\n",
    "        articles = list(pubmed.getArticles(ids))\n",
    "        logging.info(f'Fetched {len(articles)} references')\n",
    "        dict_articles = [x.toDict() for x in articles]\n",
    "        refs = pd.concat([refs, pd.DataFrame(dict_articles)], ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "refs.drop_duplicates(subset='doi', inplace=True)\n",
    "\n",
    "# Drop articles already in the base\n",
    "refs = refs[~refs.doi.isin(base.doi)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = pd.concat([base, citing, refs], ignore_index=True)\n",
    "all_articles.drop_duplicates(subset='doi', inplace=True)\n",
    "all_articles = all_articles[all_articles['publication_date'] > '1993-01-01']\n",
    "all_articles.to_csv('all_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authors statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wang', 774),\n",
       " ('zhang', 606),\n",
       " ('li', 597),\n",
       " ('liu', 517),\n",
       " ('chen', 437),\n",
       " ('yang', 311),\n",
       " ('kim', 296),\n",
       " ('lee', 235),\n",
       " ('wu', 223),\n",
       " ('huang', 204)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "authors = []\n",
    "for authorlist in all_articles['authors']:\n",
    "    authorlist = eval(authorlist)\n",
    "    authors.extend([x['lastname'].lower() for x in authorlist if x['lastname'] is not None])\n",
    "\n",
    "auth_counter = Counter(authors)\n",
    "auth_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get statistics on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nanoparticles', 323),\n",
       " ('gold nanoparticles', 161),\n",
       " ('silver nanoparticles', 148),\n",
       " ('laser ablation', 136),\n",
       " ('drug delivery', 92),\n",
       " ('nanomedicine', 71),\n",
       " ('cytotoxicity', 67),\n",
       " ('nanotechnology', 67),\n",
       " ('surface plasmon resonance', 65),\n",
       " ('cancer', 62),\n",
       " ('toxicity', 60),\n",
       " ('nanomaterials', 59),\n",
       " ('plasmonics', 54),\n",
       " ('photothermal therapy', 51),\n",
       " ('antibacterial activity', 51),\n",
       " ('sers', 49),\n",
       " ('antibacterial', 46),\n",
       " ('oxidative stress', 46),\n",
       " ('wound healing', 46),\n",
       " ('green synthesis', 45)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "kw = Counter()\n",
    "for kwlist in all_articles['keywords'].dropna():\n",
    "    kwlist = eval(kwlist)\n",
    "    kw.update([kw.lower() for kw in kwlist if kw is not None])\n",
    "kw.most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
